<configuration>
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-3level %logger{5} - %msg %n</pattern>
        </encoder>
    </appender>

     The actual AwsLogsAppender (asynchronous mode because of maxFlushTimeMillis > 0)
<!--    <appender name="ASYNC_AWS_CW_LOG" class="ca.pjer.logback.AwsLogsAppender">-->
<!--        <file>${APP_LOG_ROOT}/awsCwLog.log</file>-->
<!--        &lt;!&ndash; Send only ERROR and above &ndash;&gt;-->
<!--        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">-->
<!--            <level>INFO</level>-->
<!--        </filter>-->
<!--        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">-->
<!--            &lt;!&ndash; rollover daily &ndash;&gt;-->
<!--            <fileNamePattern>awsCwLog-%d{yyyy-MM-dd}.%i.log</fileNamePattern>-->
<!--            &lt;!&ndash; each file should be at most 100MB, keep 60 days worth of history, but at most 20GB &ndash;&gt;-->
<!--            <maxFileSize>100MB</maxFileSize>-->
<!--            <maxHistory>10</maxHistory>-->
<!--            <totalSizeCap>1GB</totalSizeCap>-->
<!--        </rollingPolicy>-->
<!--        &lt;!&ndash; Nice layout pattern &ndash;&gt;-->
<!--        <layout>-->
<!--            <pattern>[%date] %highlight([%level]) [%logger{10} %file:%line] %msg%n</pattern>-->
<!--        </layout>-->

<!--        &lt;!&ndash; Hardcoded Log Group Name &ndash;&gt;-->
<!--        <logGroupName>/aws/ec2/api/nft</logGroupName>-->

<!--        &lt;!&ndash; Log Stream Name UUID Prefix &ndash;&gt;-->
<!--        <logStreamUuidPrefix>nft-api-</logStreamUuidPrefix>-->

<!--        &lt;!&ndash; AWS Region &ndash;&gt;-->
<!--        <logRegion>ap-northeast-2</logRegion>-->

<!--        &lt;!&ndash; Maximum number of events in each batch (50 is the default) &ndash;&gt;-->
<!--        &lt;!&ndash; will flush when the event queue has 50 elements, even if still in quiet time (see maxFlushTimeMillis) &ndash;&gt;-->
<!--        <maxBatchLogEvents>50</maxBatchLogEvents>-->

<!--        &lt;!&ndash; Maximum quiet time in millisecond (0 is the default) &ndash;&gt;-->
<!--        &lt;!&ndash; will flush when met, even if the batch size is not met (see maxBatchLogEvents) &ndash;&gt;-->
<!--        <maxFlushTimeMillis>30000</maxFlushTimeMillis>-->

<!--        &lt;!&ndash; Maximum block time in millisecond (5000 is the default) &ndash;&gt;-->
<!--        &lt;!&ndash; when > 0: this is the maximum time the logging thread will wait for the logger, &ndash;&gt;-->
<!--        &lt;!&ndash; when == 0: the logging thread will never wait for the logger, discarding events while the queue is full &ndash;&gt;-->
<!--        <maxBlockTimeMillis>5000</maxBlockTimeMillis>-->

<!--        &lt;!&ndash; Retention value for log groups, 0 for infinite see &ndash;&gt;-->
<!--        &lt;!&ndash; https://docs.aws.amazon.com/AmazonCloudWatchLogs/latest/APIReference/API_PutRetentionPolicy.html for other &ndash;&gt;-->
<!--        &lt;!&ndash; possible values &ndash;&gt;-->

<!--        <retentionTimeDays>0</retentionTimeDays>-->

<!--    </appender>-->

    <timestamp key="timestamp" datePattern="yyyy-MM-dd-HH-mm-ssSSS"/>

    <logger name="jdbc" level="OFF"/>

    <logger name="jdbc.sqlonly" level="OFF"/>
    <logger name="jdbc.sqltiming" level="OFF"/>
    <logger name="jdbc.audit" level="OFF"/>
    <logger name="jdbc.resultset" level="OFF"/>
    <logger name="jdbc.resultsettable" level="OFF"/>
    <logger name="jdbc.connection" level="OFF"/>

    <root level="INFO">
        <appender-ref ref="STDOUT" />
<!--        <appender-ref ref="ASYNC_AWS_CW_LOG" />-->
    </root>

</configuration>
